{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natures Eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models, layers, regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread \n",
    "from PIL import Image\n",
    "\n",
    "# Neural network libraries\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers, optimizers, losses, metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, classification_report, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(history):\n",
    "    results = history.history\n",
    "    plt.figure()\n",
    "    plt.plot(results['val_accuracy'], label = 'Validation Accuracy')\n",
    "    plt.plot(results['accuracy'], label = 'Train Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(results['val_recall'], label = 'Validation Recall')\n",
    "    plt.plot(results['recall'], label = 'Train Recall')\n",
    "    plt.title('Recall Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(results['val_loss'], label = 'Validation Loss')\n",
    "    plt.plot(results['loss'], label = 'Train Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to display confusion matrices for models\n",
    "def conf_mat(model):\n",
    "    y_pred = model.predict(test_set)\n",
    "    y_pred = (y_pred>0.5).astype(np.int)\n",
    "    display(ConfusionMatrixDisplay(confusion_matrix(test_set.classes, y_pred), display_labels=['Normal', 'Pneumonia']).plot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5400 images belonging to 90 classes.\n"
     ]
    }
   ],
   "source": [
    "#train_data_dir = 'ZhangLabData/CellData/chest_xray/train'\n",
    "train_path = 'archive/animals'\n",
    "\n",
    "#Get all the data in the directory data/validation (624 images), and reshape them\n",
    "#test_generator = ImageDataGenerator().flow_from_directory(\n",
    "#       test_data_dir, \n",
    "#       target_size=(64, 64), batch_size=624, color_mode='grayscale', class_mode='binary')\n",
    "\n",
    "#Get all the data in the directory data/train (5232 images), and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "       train_path, \n",
    "       target_size=(64, 64), color_mode='rgb', class_mode='categorical')\n",
    "\n",
    "#Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "#test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_labels[:10]\n",
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antelope': 0,\n",
       " 'badger': 1,\n",
       " 'bat': 2,\n",
       " 'bear': 3,\n",
       " 'bee': 4,\n",
       " 'beetle': 5,\n",
       " 'bison': 6,\n",
       " 'boar': 7,\n",
       " 'butterfly': 8,\n",
       " 'cat': 9,\n",
       " 'caterpillar': 10,\n",
       " 'chimpanzee': 11,\n",
       " 'cockroach': 12,\n",
       " 'cow': 13,\n",
       " 'coyote': 14,\n",
       " 'crab': 15,\n",
       " 'crow': 16,\n",
       " 'deer': 17,\n",
       " 'dog': 18,\n",
       " 'dolphin': 19,\n",
       " 'donkey': 20,\n",
       " 'dragonfly': 21,\n",
       " 'duck': 22,\n",
       " 'eagle': 23,\n",
       " 'elephant': 24,\n",
       " 'flamingo': 25,\n",
       " 'fly': 26,\n",
       " 'fox': 27,\n",
       " 'goat': 28,\n",
       " 'goldfish': 29,\n",
       " 'goose': 30,\n",
       " 'gorilla': 31,\n",
       " 'grasshopper': 32,\n",
       " 'hamster': 33,\n",
       " 'hare': 34,\n",
       " 'hedgehog': 35,\n",
       " 'hippopotamus': 36,\n",
       " 'hornbill': 37,\n",
       " 'horse': 38,\n",
       " 'hummingbird': 39,\n",
       " 'hyena': 40,\n",
       " 'jellyfish': 41,\n",
       " 'kangaroo': 42,\n",
       " 'koala': 43,\n",
       " 'ladybugs': 44,\n",
       " 'leopard': 45,\n",
       " 'lion': 46,\n",
       " 'lizard': 47,\n",
       " 'lobster': 48,\n",
       " 'mosquito': 49,\n",
       " 'moth': 50,\n",
       " 'mouse': 51,\n",
       " 'octopus': 52,\n",
       " 'okapi': 53,\n",
       " 'orangutan': 54,\n",
       " 'otter': 55,\n",
       " 'owl': 56,\n",
       " 'ox': 57,\n",
       " 'oyster': 58,\n",
       " 'panda': 59,\n",
       " 'parrot': 60,\n",
       " 'pelecaniformes': 61,\n",
       " 'penguin': 62,\n",
       " 'pig': 63,\n",
       " 'pigeon': 64,\n",
       " 'porcupine': 65,\n",
       " 'possum': 66,\n",
       " 'raccoon': 67,\n",
       " 'rat': 68,\n",
       " 'reindeer': 69,\n",
       " 'rhinoceros': 70,\n",
       " 'sandpiper': 71,\n",
       " 'seahorse': 72,\n",
       " 'seal': 73,\n",
       " 'shark': 74,\n",
       " 'sheep': 75,\n",
       " 'snake': 76,\n",
       " 'sparrow': 77,\n",
       " 'squid': 78,\n",
       " 'squirrel': 79,\n",
       " 'starfish': 80,\n",
       " 'swan': 81,\n",
       " 'tiger': 82,\n",
       " 'turkey': 83,\n",
       " 'turtle': 84,\n",
       " 'whale': 85,\n",
       " 'wolf': 86,\n",
       " 'wombat': 87,\n",
       " 'woodpecker': 88,\n",
       " 'zebra': 89}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set from training set\n",
    "\n",
    "X = train_images\n",
    "y = train_labels\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dummy classifer/regressor for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummy classifer/regressor for baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy='uniform')\n",
    "dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ee0b70bc35d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     cm = confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    221\u001b[0m                           labels=labels, normalize=normalize)\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(dummy, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creation of neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                81940     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 147       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 82,133\n",
      "Trainable params: 82,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creation of neural network model\n",
    "simple_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(64, 64, 1)),\n",
    "    layers.Dense(20, activation='relu'),\n",
    "    layers.Dense(7, activation='relu'),\n",
    "    layers.Dense(5, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "simple_model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['categorical_accuracy', metrics.Recall(name='recall'), metrics.AUC(name='auc'), metrics.AUC(name='prc', curve='PR')])\n",
    "\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"flatten_input:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 4096 but received input with shape [None, 12288]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-4e5b98c3b070>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the train_set data to the simple model built above and use validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m simple_history = simple_model.fit(X_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     validation_data=y_train.all())\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 4096 but received input with shape [None, 12288]\n"
     ]
    }
   ],
   "source": [
    "# Fit the train_set data to the simple model built above and use validation set \n",
    "simple_history = simple_model.fit(X_train,\n",
    "                    epochs=3,\n",
    "                    batch_size=32,\n",
    "                    validation_data=y_train.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(simple_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=5, strides=2, activation='relu', input_shape=(268, 182, 3)))\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))       \n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))   # Final Layer using Softmax\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 1) for input Tensor(\"flatten_input:0\", shape=(None, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (None, 64, 64, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 4096 but received input with shape [None, 12288]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-10a779e07b8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the train_set data to the simple model built above and use validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m simple_history = simple_model.fit(X_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\danie\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 4096 but received input with shape [None, 12288]\n"
     ]
    }
   ],
   "source": [
    "# Fit the train_set data to the simple model built above and use validation set \n",
    "simple_history = simple_model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=3,\n",
    "                    batch_size=32,\n",
    "                    validation_data= (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\danie\\anaconda3\\envs\\learn-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - cpuonly\n",
      "    - pytorch\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2021.10.26 |       haa95532_2         115 KB\n",
      "    certifi-2021.10.8          |   py38haa95532_2         152 KB\n",
      "    cpuonly-2.0                |                0           2 KB  pytorch\n",
      "    libuv-1.40.0               |       he774522_0         255 KB\n",
      "    openssl-1.1.1m             |       h2bbff1b_0         4.8 MB\n",
      "    pytorch-1.10.1             |      py3.8_cpu_0       193.1 MB  pytorch\n",
      "    pytorch-mutex-1.0          |              cpu           3 KB  pytorch\n",
      "    torchvision-0.11.2         |         py38_cpu         7.2 MB  pytorch\n",
      "    typing_extensions-3.10.0.2 |     pyh06a4308_0          31 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       205.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cpuonly            pytorch/noarch::cpuonly-2.0-0\n",
      "  libuv              pkgs/main/win-64::libuv-1.40.0-he774522_0\n",
      "  pytorch            pytorch/win-64::pytorch-1.10.1-py3.8_cpu_0\n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cpu\n",
      "  torchvision        pytorch/win-64::torchvision-0.11.2-py38_cpu\n",
      "  typing_extensions  pkgs/main/noarch::typing_extensions-3.10.0.2-pyh06a4308_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2020.10.14-haa95532_1 --> 2021.10.26-haa95532_2\n",
      "  certifi            conda-forge::certifi-2020.6.20-py38h9~ --> pkgs/main::certifi-2021.10.8-py38haa95532_2\n",
      "  openssl            conda-forge::openssl-1.1.1h-he774522_0 --> pkgs/main::openssl-1.1.1m-h2bbff1b_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "pytorch-1.10.1       | 193.1 MB  |            |   0% \n",
      "pytorch-1.10.1       | 193.1 MB  |            |   0% \n",
      "pytorch-1.10.1       | 193.1 MB  |            |   0% \n",
      "pytorch-1.10.1       | 193.1 MB  |            |   0% \n",
      "pytorch-1.10.1       | 193.1 MB  |            |   0% \n",
      "pytorch-1.10.1       | 193.1 MB  |            |   0% \n",
      "pytorch-1.10.1       | 193.1 MB  |            |   1% \n",
      "pytorch-1.10.1       | 193.1 MB  |            |   1% \n",
      "pytorch-1.10.1       | 193.1 MB  |            |   1% \n",
      "pytorch-1.10.1       | 193.1 MB  | 1          |   1% \n",
      "pytorch-1.10.1       | 193.1 MB  | 1          |   1% \n",
      "pytorch-1.10.1       | 193.1 MB  | 1          |   1% \n",
      "pytorch-1.10.1       | 193.1 MB  | 1          |   1% \n",
      "pytorch-1.10.1       | 193.1 MB  | 1          |   2% \n",
      "pytorch-1.10.1       | 193.1 MB  | 1          |   2% \n",
      "pytorch-1.10.1       | 193.1 MB  | 1          |   2% \n",
      "pytorch-1.10.1       | 193.1 MB  | 1          |   2% \n",
      "pytorch-1.10.1       | 193.1 MB  | 2          |   2% \n",
      "pytorch-1.10.1       | 193.1 MB  | 2          |   2% \n",
      "pytorch-1.10.1       | 193.1 MB  | 2          |   2% \n",
      "pytorch-1.10.1       | 193.1 MB  | 2          |   3% \n",
      "pytorch-1.10.1       | 193.1 MB  | 2          |   3% \n",
      "pytorch-1.10.1       | 193.1 MB  | 2          |   3% \n",
      "pytorch-1.10.1       | 193.1 MB  | 2          |   3% \n",
      "pytorch-1.10.1       | 193.1 MB  | 3          |   3% \n",
      "pytorch-1.10.1       | 193.1 MB  | 3          |   3% \n",
      "pytorch-1.10.1       | 193.1 MB  | 3          |   3% \n",
      "pytorch-1.10.1       | 193.1 MB  | 3          |   4% \n",
      "pytorch-1.10.1       | 193.1 MB  | 3          |   4% \n",
      "pytorch-1.10.1       | 193.1 MB  | 3          |   4% \n",
      "pytorch-1.10.1       | 193.1 MB  | 3          |   4% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   4% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   4% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   4% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   4% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   5% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   5% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   5% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   5% \n",
      "pytorch-1.10.1       | 193.1 MB  | 4          |   5% \n",
      "pytorch-1.10.1       | 193.1 MB  | 5          |   5% \n",
      "pytorch-1.10.1       | 193.1 MB  | 5          |   5% \n",
      "pytorch-1.10.1       | 193.1 MB  | 5          |   5% \n",
      "pytorch-1.10.1       | 193.1 MB  | 5          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 5          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 5          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 5          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 5          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   6% \n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   7% \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 6          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   7% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 7          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   8% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 8          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |   9% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | 9          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  10% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #          |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  11% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #1         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  12% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #2         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  13% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #3         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  14% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #4         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  15% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #5         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  16% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #6         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #7         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #7         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #7         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #7         |  17% \n",
      "pytorch-1.10.1       | 193.1 MB  | #7         |  18% \n",
      "pytorch-1.10.1       | 193.1 MB  | #7         |  18% \n",
      "pytorch-1.10.1       | 193.1 MB  | #7         |  18% \n",
      "pytorch-1.10.1       | 193.1 MB  | #8         |  18% \n",
      "pytorch-1.10.1       | 193.1 MB  | #8         |  18% \n",
      "pytorch-1.10.1       | 193.1 MB  | #8         |  18% \n",
      "pytorch-1.10.1       | 193.1 MB  | #8         |  18% \n",
      "pytorch-1.10.1       | 193.1 MB  | #8         |  19% \n",
      "pytorch-1.10.1       | 193.1 MB  | #8         |  19% \n",
      "pytorch-1.10.1       | 193.1 MB  | #8         |  19% \n",
      "pytorch-1.10.1       | 193.1 MB  | #8         |  19% \n",
      "pytorch-1.10.1       | 193.1 MB  | #9         |  19% \n",
      "pytorch-1.10.1       | 193.1 MB  | #9         |  19% \n",
      "pytorch-1.10.1       | 193.1 MB  | #9         |  19% \n",
      "pytorch-1.10.1       | 193.1 MB  | #9         |  20% \n",
      "pytorch-1.10.1       | 193.1 MB  | #9         |  20% \n",
      "pytorch-1.10.1       | 193.1 MB  | #9         |  20% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##         |  20% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##         |  20% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##         |  20% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##         |  21% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##         |  21% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##         |  21% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##1        |  21% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##1        |  21% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##1        |  22% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##1        |  22% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##2        |  22% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##2        |  22% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##2        |  22% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##2        |  23% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##2        |  23% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##3        |  23% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##3        |  23% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##3        |  23% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##3        |  24% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##3        |  24% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##4        |  24% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##4        |  24% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##4        |  24% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##4        |  25% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##4        |  25% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##5        |  25% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##5        |  25% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##5        |  25% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##5        |  26% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##5        |  26% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##6        |  26% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##6        |  26% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##6        |  26% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##6        |  27% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##6        |  27% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##7        |  27% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##7        |  27% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##7        |  28% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##7        |  28% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##8        |  28% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##8        |  28% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##8        |  28% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##8        |  29% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##9        |  29% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##9        |  29% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##9        |  30% \n",
      "pytorch-1.10.1       | 193.1 MB  | ##9        |  30% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###        |  30% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###        |  30% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###        |  31% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###        |  31% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###1       |  31% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###1       |  31% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###1       |  32% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###2       |  32% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###2       |  32% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###2       |  33% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###2       |  33% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###3       |  33% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###3       |  33% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###3       |  34% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###3       |  34% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###4       |  34% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###4       |  34% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###4       |  35% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###4       |  35% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###5       |  35% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###5       |  35% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###5       |  36% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###5       |  36% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###6       |  36% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###6       |  36% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###6       |  37% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###6       |  37% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###7       |  37% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###7       |  38% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###7       |  38% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###8       |  38% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###8       |  38% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###8       |  39% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###8       |  39% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###9       |  39% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###9       |  40% \n",
      "pytorch-1.10.1       | 193.1 MB  | ###9       |  40% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####       |  40% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####       |  40% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####       |  41% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####       |  41% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####1      |  41% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####1      |  42% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####1      |  42% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####2      |  42% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####2      |  42% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####2      |  43% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####2      |  43% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####3      |  43% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####3      |  44% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####3      |  44% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####4      |  44% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####4      |  44% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-1.10.1       | 193.1 MB  | ####4      |  45% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####4      |  45% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####5      |  45% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####5      |  45% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####5      |  46% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####6      |  46% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####6      |  46% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####6      |  47% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####6      |  47% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####7      |  47% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####7      |  48% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####7      |  48% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####8      |  48% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####8      |  48% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####8      |  49% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####8      |  49% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####9      |  49% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####9      |  50% \n",
      "pytorch-1.10.1       | 193.1 MB  | ####9      |  50% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####      |  50% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####      |  50% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####      |  51% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####      |  51% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####1     |  51% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####1     |  51% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####1     |  52% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####1     |  52% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####2     |  52% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####2     |  52% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####2     |  53% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####2     |  53% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####3     |  53% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####3     |  53% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####3     |  54% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####4     |  54% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####4     |  54% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####4     |  55% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####4     |  55% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####5     |  55% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####5     |  55% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####5     |  56% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####6     |  56% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####6     |  56% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####6     |  57% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####6     |  57% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####7     |  57% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####7     |  57% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####7     |  58% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####8     |  58% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####8     |  58% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####8     |  59% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####8     |  59% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####9     |  59% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####9     |  59% \n",
      "pytorch-1.10.1       | 193.1 MB  | #####9     |  60% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######     |  60% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######     |  60% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######     |  61% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######     |  61% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######1    |  61% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######1    |  61% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######1    |  62% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######1    |  62% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######2    |  62% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######2    |  62% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######2    |  63% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######2    |  63% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######3    |  63% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######3    |  63% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######3    |  64% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######4    |  64% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######4    |  64% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######4    |  65% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######4    |  65% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######5    |  65% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######5    |  65% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######5    |  66% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######5    |  66% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######6    |  66% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######6    |  66% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######6    |  67% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######6    |  67% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######7    |  67% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######7    |  67% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######7    |  68% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######8    |  68% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######8    |  68% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######8    |  69% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######8    |  69% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######9    |  69% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######9    |  69% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######9    |  70% \n",
      "pytorch-1.10.1       | 193.1 MB  | ######9    |  70% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######    |  70% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######    |  70% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######    |  71% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######    |  71% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######1   |  71% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######1   |  71% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######1   |  72% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######1   |  72% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######2   |  72% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######2   |  72% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######2   |  73% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######3   |  73% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######3   |  73% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######3   |  74% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######3   |  74% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######4   |  74% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######4   |  74% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######4   |  75% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######4   |  75% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######5   |  75% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######5   |  75% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######5   |  76% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######5   |  76% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######6   |  76% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######6   |  76% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######6   |  77% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######6   |  77% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######7   |  77% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######7   |  78% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######7   |  78% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######8   |  78% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######8   |  78% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######8   |  79% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######8   |  79% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######9   |  79% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######9   |  79% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######9   |  80% \n",
      "pytorch-1.10.1       | 193.1 MB  | #######9   |  80% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########   |  80% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########   |  81% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########   |  81% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########1  |  81% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########1  |  81% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########1  |  82% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########1  |  82% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########2  |  82% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########2  |  82% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########2  |  83% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########3  |  83% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########3  |  83% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########3  |  84% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########3  |  84% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########4  |  84% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########4  |  84% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########4  |  85% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########4  |  85% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########5  |  85% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########5  |  85% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########5  |  86% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########5  |  86% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########6  |  86% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########6  |  86% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########6  |  87% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########6  |  87% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########7  |  87% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########7  |  87% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########7  |  88% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########7  |  88% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########8  |  88% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########8  |  88% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########8  |  89% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########8  |  89% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########9  |  89% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########9  |  89% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########9  |  90% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########9  |  90% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########  |  90% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########  |  90% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########  |  91% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########  |  91% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########1 |  91% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########1 |  91% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########1 |  92% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########1 |  92% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########2 |  92% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########2 |  92% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########2 |  93% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########2 |  93% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########3 |  93% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########3 |  93% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########3 |  94% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########4 |  94% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########4 |  94% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########4 |  94% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########4 |  95% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########4 |  95% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########5 |  95% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########5 |  96% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########5 |  96% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########6 |  96% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########6 |  96% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########6 |  97% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########6 |  97% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########7 |  97% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########7 |  97% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########7 |  98% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########7 |  98% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########8 |  98% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########8 |  98% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########8 |  99% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########9 |  99% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########9 |  99% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########9 | 100% \n",
      "pytorch-1.10.1       | 193.1 MB  | #########9 | 100% \n",
      "pytorch-1.10.1       | 193.1 MB  | ########## | 100% \n",
      "\n",
      "libuv-1.40.0         | 255 KB    |            |   0% \n",
      "libuv-1.40.0         | 255 KB    | 6          |   6% \n",
      "libuv-1.40.0         | 255 KB    | ########## | 100% \n",
      "libuv-1.40.0         | 255 KB    | ########## | 100% \n",
      "\n",
      "typing_extensions-3. | 31 KB     |            |   0% \n",
      "typing_extensions-3. | 31 KB     | ########## | 100% \n",
      "typing_extensions-3. | 31 KB     | ########## | 100% \n",
      "\n",
      "cpuonly-2.0          | 2 KB      |            |   0% \n",
      "cpuonly-2.0          | 2 KB      | ########## | 100% \n",
      "cpuonly-2.0          | 2 KB      | ########## | 100% \n",
      "\n",
      "certifi-2021.10.8    | 152 KB    |            |   0% \n",
      "certifi-2021.10.8    | 152 KB    | ########## | 100% \n",
      "certifi-2021.10.8    | 152 KB    | ########## | 100% \n",
      "\n",
      "pytorch-mutex-1.0    | 3 KB      |            |   0% \n",
      "pytorch-mutex-1.0    | 3 KB      | ########## | 100% \n",
      "pytorch-mutex-1.0    | 3 KB      | ########## | 100% \n",
      "\n",
      "ca-certificates-2021 | 115 KB    |            |   0% \n",
      "ca-certificates-2021 | 115 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1m       | 4.8 MB    |            |   0% \n",
      "openssl-1.1.1m       | 4.8 MB    | 5          |   6% \n",
      "openssl-1.1.1m       | 4.8 MB    | #5         |  15% \n",
      "openssl-1.1.1m       | 4.8 MB    | ##2        |  23% \n",
      "openssl-1.1.1m       | 4.8 MB    | ###2       |  33% \n",
      "openssl-1.1.1m       | 4.8 MB    | ####1      |  41% \n",
      "openssl-1.1.1m       | 4.8 MB    | #####2     |  52% \n",
      "openssl-1.1.1m       | 4.8 MB    | ######1    |  62% \n",
      "openssl-1.1.1m       | 4.8 MB    | #######    |  71% \n",
      "openssl-1.1.1m       | 4.8 MB    | #######8   |  79% \n",
      "openssl-1.1.1m       | 4.8 MB    | ########9  |  90% \n",
      "openssl-1.1.1m       | 4.8 MB    | ########## | 100% \n",
      "openssl-1.1.1m       | 4.8 MB    | ########## | 100% \n",
      "\n",
      "torchvision-0.11.2   | 7.2 MB    |            |   0% \n",
      "torchvision-0.11.2   | 7.2 MB    |            |   0% \n",
      "torchvision-0.11.2   | 7.2 MB    |            |   1% \n",
      "torchvision-0.11.2   | 7.2 MB    | 3          |   4% \n",
      "torchvision-0.11.2   | 7.2 MB    | 9          |  10% \n",
      "torchvision-0.11.2   | 7.2 MB    | #6         |  16% \n",
      "torchvision-0.11.2   | 7.2 MB    | ##2        |  22% \n",
      "torchvision-0.11.2   | 7.2 MB    | ##9        |  30% \n",
      "torchvision-0.11.2   | 7.2 MB    | ###5       |  36% \n",
      "torchvision-0.11.2   | 7.2 MB    | ####2      |  42% \n",
      "torchvision-0.11.2   | 7.2 MB    | ####8      |  48% \n",
      "torchvision-0.11.2   | 7.2 MB    | #####5     |  56% \n",
      "torchvision-0.11.2   | 7.2 MB    | ######2    |  63% \n",
      "torchvision-0.11.2   | 7.2 MB    | ######9    |  69% \n",
      "torchvision-0.11.2   | 7.2 MB    | #######6   |  76% \n",
      "torchvision-0.11.2   | 7.2 MB    | ########3  |  83% \n",
      "torchvision-0.11.2   | 7.2 MB    | ########9  |  90% \n",
      "torchvision-0.11.2   | 7.2 MB    | #########6 |  96% \n",
      "torchvision-0.11.2   | 7.2 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\danie\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.11.0               |   py38haa95532_0        14.4 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        14.4 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.10.3-py38haa95532_0 --> 4.11.0-py38haa95532_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.11.0         | 14.4 MB   |            |   0% \n",
      "conda-4.11.0         | 14.4 MB   |            |   0% \n",
      "conda-4.11.0         | 14.4 MB   | 3          |   3% \n",
      "conda-4.11.0         | 14.4 MB   | 6          |   6% \n",
      "conda-4.11.0         | 14.4 MB   | 9          |  10% \n",
      "conda-4.11.0         | 14.4 MB   | #2         |  13% \n",
      "conda-4.11.0         | 14.4 MB   | #5         |  16% \n",
      "conda-4.11.0         | 14.4 MB   | #8         |  19% \n",
      "conda-4.11.0         | 14.4 MB   | ##1        |  21% \n",
      "conda-4.11.0         | 14.4 MB   | ##4        |  24% \n",
      "conda-4.11.0         | 14.4 MB   | ##6        |  27% \n",
      "conda-4.11.0         | 14.4 MB   | ###        |  30% \n",
      "conda-4.11.0         | 14.4 MB   | ###3       |  34% \n",
      "conda-4.11.0         | 14.4 MB   | ###7       |  37% \n",
      "conda-4.11.0         | 14.4 MB   | ###9       |  40% \n",
      "conda-4.11.0         | 14.4 MB   | ####2      |  43% \n",
      "conda-4.11.0         | 14.4 MB   | ####5      |  46% \n",
      "conda-4.11.0         | 14.4 MB   | ####8      |  48% \n",
      "conda-4.11.0         | 14.4 MB   | #####1     |  51% \n",
      "conda-4.11.0         | 14.4 MB   | #####4     |  54% \n",
      "conda-4.11.0         | 14.4 MB   | #####7     |  58% \n",
      "conda-4.11.0         | 14.4 MB   | ######1    |  62% \n",
      "conda-4.11.0         | 14.4 MB   | ######5    |  65% \n",
      "conda-4.11.0         | 14.4 MB   | ######8    |  69% \n",
      "conda-4.11.0         | 14.4 MB   | #######1   |  72% \n",
      "conda-4.11.0         | 14.4 MB   | #######5   |  75% \n",
      "conda-4.11.0         | 14.4 MB   | #######8   |  79% \n",
      "conda-4.11.0         | 14.4 MB   | ########1  |  82% \n",
      "conda-4.11.0         | 14.4 MB   | ########5  |  85% \n",
      "conda-4.11.0         | 14.4 MB   | ########8  |  88% \n",
      "conda-4.11.0         | 14.4 MB   | #########1 |  92% \n",
      "conda-4.11.0         | 14.4 MB   | #########4 |  95% \n",
      "conda-4.11.0         | 14.4 MB   | #########7 |  97% \n",
      "conda-4.11.0         | 14.4 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5a6b601f89fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import datasets, transforms, models \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ''archive/animals'\n",
    "classes = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform=transforms.Compose([\n",
    "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
    "        transforms.Resize(100),             # resize shortest side to 100 pixels\n",
    "        transforms.CenterCrop(100),         # crop longest side to 100 pixels at center\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(data_dir, transform=train_transform)\n",
    "print('Size of training dataset :', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view one image shape of the dataset.\n",
    "img, label = dataset[100]\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the showing the image.\n",
    "def show_image(img, label):\n",
    "    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(*dataset[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20)\n",
    "val_size = len(dataset)//10\n",
    "test_size = len(dataset)//5\n",
    "train_size = len(dataset) - val_size -test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "len(train_ds), len(val_ds),len(test_ds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    fig, ax = plt.subplots(figsize=(18,10))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)\n",
    "test_loader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3*100*100\n",
    "output_size = 91 # Number of classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ImageClassificationBase):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.in_layer = nn.Linear(input_size, 8384)\n",
    "        self.hidden1 = nn.Linear(8384, 4192)\n",
    "        self.hidden2 = nn.Linear(4192, 2096)\n",
    "        self.hidden3 = nn.Linear(2096, 1048)\n",
    "        self.out_layer = nn.Linear(1048, output_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # Flatten images into vectors\n",
    "        out = xb.view(xb.size(0), -1)\n",
    "        out = self.in_layer(out)\n",
    "        out = self.hidden1(F.relu(out))\n",
    "        out = self.hidden2(F.relu(out))\n",
    "        out = self.hidden3(F.relu(out))\n",
    "        out = self.out_layer(F.relu(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(Model(input_size, output_size), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [evaluate(model, val_loader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history += fit(7, 0.01, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history += fit(8, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history += fit(3, 0.0001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for n in range(5):\n",
    "    normal_img = os.listdir(train_data_dir/bat')[n]\n",
    "    normal_img_address = train_data_dir\n",
    "    normal_load = Image.open(normal_img_address, 'r')\n",
    "    ax = plt.subplot(5,5,n+1)\n",
    "    plt.imshow(normal_load, cmap ='rgb')\n",
    "    plt.title(\"NORMAL\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_load = Image.open(train_bat, 'r')\n",
    "#ax = plt.subplot(5,5,n+1)\n",
    "#plt.imshow(normal_load, cmap ='rgb')\n",
    "#plt.title(\"NORMAL\")\n",
    "#plt.axis(\"off\")\n",
    "type(normal_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn dummy classifer that will always return the most frequent class (pneumonia)\n",
    "baseline_model = DummyClassifier(strategy='most_frequent')\n",
    "baseline_model.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring dummy model for accuracy and recall\n",
    "base_acc = baseline_model.score(test_images, test_labels)\n",
    "print(base_acc)\n",
    "\n",
    "# Generate predicts using model\n",
    "y_pred_base = baseline_model.predict(test_images)\n",
    "\n",
    "# Recall score\n",
    "base_recall = recall_score(test_labels, y_pred_base)\n",
    "print(base_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix for dummy model\n",
    "plot_confusion_matrix(baseline_model, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'archive/animals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utlize ImageDataGenerator from keras.preprocessing\n",
    "img_dgen = ImageDataGenerator(rescale=1./255, validation_split = 0.20)\n",
    "\n",
    "# Creation of train set, note the subset argument due to the validation split\n",
    "train_set = img_dgen.flow_from_directory(train_path, target_size=(64, 64), \n",
    "                                         color_mode='grayscale', subset='training')\n",
    "\n",
    "# Creation of validation set from 20% of the train data\n",
    "validation_set = img_dgen.flow_from_directory(train_path, target_size=(64, 64), \n",
    "                                         color_mode='grayscale', subset='validation')\n",
    "\n",
    "# Creation of test set from the test path, shuffle set to false for use in future model predictions\n",
    "#test_set = img_dgen.flow_from_directory(test_path, target_size=(64, 64), \n",
    "#                                         color_mode='grayscale', class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size set to the number of images found above in order to not batch data for the dummy model. Validation set not needed for dummy model\n",
    "train_set_dummy = img_dgen.flow_from_directory(train_path,\n",
    "                                               target_size=(64, 64),\n",
    "                                               color_mode='rgb', \n",
    "                                               class_mode='categorical', \n",
    "                                               subset='training', \n",
    "                                               batch_size=4000)\n",
    "\n",
    "test_set_dummy = img_dgen.flow_from_directory(validation_set, \n",
    "                                              target_size=(64, 64),\n",
    "                                              color_mode='rgb',\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=False,\n",
    "                                              batch_size=1400)\n",
    "\n",
    "# Split train and test dummy sets into images and corresponding labels for dummy model training\n",
    "train_images, train_labels = next(train_set_dummy)\n",
    "test_images, test_labels = next(test_set_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring dummy model for accuracy and recall\n",
    "base_acc = baseline_model.score(test_images, test_labels)\n",
    "print(base_acc)\n",
    "\n",
    "# Generate predicts using model\n",
    "y_pred_base = baseline_model.predict(test_images)\n",
    "\n",
    "# Recall score\n",
    "base_recall = recall_score(test_labels, y_pred_base)\n",
    "print(base_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
